{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31f5cb6f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m \n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      8\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m graph_objs \u001b[38;5;28;01mas\u001b[39;00m go\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import numpy as np \n",
    "import random\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from plotly import graph_objs as go\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "from collections import Counter\n",
    "\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import nltk\n",
    "import spacy\n",
    "import random\n",
    "from spacy.util import compounding\n",
    "from spacy.util import minibatch\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6127e7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_colours(number_of_colors):\n",
    "    '''\n",
    "    Simple function for random colours generation.\n",
    "    Input:\n",
    "        number_of_colors - integer value indicating the number of colours which are going to be generated.\n",
    "    Output:\n",
    "        Color in the following format: ['#E86DA4'] .\n",
    "    '''\n",
    "    colors = []\n",
    "    for i in range(number_of_colors):\n",
    "        colors.append(\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)]))\n",
    "    return colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4cf4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(r\"C:/Users/me1awq/PhD/docsim/datasets/open_source/SICK_train2.csv\")\n",
    "test = pd.read_csv(r\"C:/Users/me1awq/PhD/docsim/datasets/open_source/SICK_train3.csv\")\n",
    "ss = pd.read_csv(r\"C:/Users/me1awq/PhD/docsim/datasets/open_source/SICK_train4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00da98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935af738",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f2fd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee61c93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260cb69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7547b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf923f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = train.groupby('entailment_judgment').count()['sentence_A'].reset_index().sort_values(by='sentence_A',ascending=False)\n",
    "temp.style.background_gradient(cmap='Purples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c917b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.countplot(x='entailment_judgment',data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4523c520",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard(str1, str2): \n",
    "    a = set(str1.lower().split()) \n",
    "    b = set(str2.lower().split())\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05d9457",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_jaccard=[]\n",
    "\n",
    "for ind,row in train.iterrows():\n",
    "    sentence1 = row.sentence_A\n",
    "    sentence2 = row.sentence_B\n",
    "\n",
    "    jaccard_score = jaccard(sentence1,sentence2)\n",
    "    results_jaccard.append([sentence1,sentence2,jaccard_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a94591",
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard = pd.DataFrame(results_jaccard,columns=[\"row.sentence_A\",\"row.sentence_B\",\"jaccard_score\"])\n",
    "train = train.merge(jaccard, how=\"outer\", left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e179a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Num_words_ST'] = train['row.sentence_B'].apply(lambda x:len(str(x).split())) #Number Of words in Selected Text\n",
    "train['Num_word_text'] = train['row.sentence_A'].apply(lambda x:len(str(x).split())) #Number Of words in main text\n",
    "train['difference_in_words'] = train['Num_word_text'] - train['Num_words_ST'] #Difference in Number of words text and Selected Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869fb010",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531709a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_data = [train['Num_words_ST'],train['Num_word_text']]\n",
    "\n",
    "group_labels = ['row.sentence_B', 'row.sentence_A']\n",
    "\n",
    "# Create distplot with custom bin_size\n",
    "fig = ff.create_distplot(hist_data, group_labels,show_curve=False)\n",
    "fig.update_layout(title_text='Distribution of Number Of words')\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=900,\n",
    "    height=700,\n",
    "    paper_bgcolor=\"LightSteelBlue\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab18611",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "p1=sns.kdeplot(train['Num_words_ST'], shade=True, color=\"r\").set_title('Kernel Distribution of Number Of words')\n",
    "p1=sns.kdeplot(train['Num_word_text'], shade=True, color=\"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcfc161",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "p1=sns.kdeplot(train[train['entailment_judgment']=='ENTAILMENT']['difference_in_words'], shade=True, color=\"b\").set_title('Kernel Distribution of Difference in Number Of words')\n",
    "p2=sns.kdeplot(train[train['entailment_judgment']=='CONTRADICTION']['difference_in_words'], shade=True, color=\"r\")\n",
    "p3=sns.kdeplot(train[train['entailment_judgment']=='NEUTRAL']['difference_in_words'], shade=True, color=\"g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5866c7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = train[train['Num_word_text']<=20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c361c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "k.groupby('entailment_judgment').mean()['jaccard_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93a03ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "k[k['entailment_judgment']=='ENTAILMENT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faedbd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n",
    "    and remove words containing numbers.'''\n",
    "    text = str(text).lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b779b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['sentence_A'] = train['sentence_A'].apply(lambda x:clean_text(x))\n",
    "train['sentence_B'] = train['sentence_B'].apply(lambda x:clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0018b31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e656a181",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['temp_list'] = train['sentence_B'].apply(lambda x:str(x).split())\n",
    "top = Counter([item for sublist in train['temp_list'] for item in sublist])\n",
    "temp = pd.DataFrame(top.most_common(20))\n",
    "temp.columns = ['Common_words','count']\n",
    "temp.style.background_gradient(cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51166aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(temp, x=\"count\", y=\"Common_words\", title='Commmon Words in sentence_B', orientation='h', \n",
    "             width=700, height=700,color='Common_words')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16455ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopword(x):\n",
    "    return [y for y in x if y not in stopwords.words('english')]\n",
    "train['temp_list'] = train['temp_list'].apply(lambda x:remove_stopword(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103b899d",
   "metadata": {},
   "outputs": [],
   "source": [
    "top = Counter([item for sublist in train['temp_list'] for item in sublist])\n",
    "temp = pd.DataFrame(top.most_common(20))\n",
    "temp = temp.iloc[1:,:]\n",
    "temp.columns = ['Common_words','count']\n",
    "temp.style.background_gradient(cmap='Purples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3a0795",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.treemap(temp, path=['Common_words'], values='count',title='Tree of Most Common Words')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8041b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['temp_list1'] = train['sentence_A'].apply(lambda x:str(x).split()) #List of words in every row for text\n",
    "train['temp_list1'] = train['temp_list1'].apply(lambda x:remove_stopword(x)) #Removing Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f0a90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "top = Counter([item for sublist in train['temp_list1'] for item in sublist])\n",
    "temp = pd.DataFrame(top.most_common(25))\n",
    "temp = temp.iloc[1:,:]\n",
    "temp.columns = ['Common_words','count']\n",
    "temp.style.background_gradient(cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d113468a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(temp, x=\"count\", y=\"Common_words\", title='Commmon Words in Text', orientation='h', \n",
    "             width=700, height=700,color='Common_words')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b36eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Positive_sent = train[train['entailment_judgment']=='ENTAILMENT']\n",
    "Negative_sent = train[train['entailment_judgment']=='CONTRADICTION']\n",
    "Neutral_sent = train[train['entailment_judgment']=='NEUTRAL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08d0298",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MosT common positive words\n",
    "top = Counter([item for sublist in Positive_sent['temp_list'] for item in sublist])\n",
    "temp_positive = pd.DataFrame(top.most_common(30))\n",
    "temp_positive.columns = ['Common_words','count']\n",
    "temp_positive.style.background_gradient(cmap='Greens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28feb550",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(temp_positive, x=\"count\", y=\"Common_words\", title='Most Commmon Positive Words', orientation='h', \n",
    "             width=700, height=700,color='Common_words')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e7d2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MosT common negative words\n",
    "top = Counter([item for sublist in Negative_sent['temp_list'] for item in sublist])\n",
    "temp_negative = pd.DataFrame(top.most_common(20))\n",
    "temp_negative = temp_negative.iloc[1:,:]\n",
    "temp_negative.columns = ['Common_words','count']\n",
    "temp_negative.style.background_gradient(cmap='Reds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2829f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.treemap(temp_negative, path=['Common_words'], values='count',title='Tree Of Most Common Contradicting Words')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199f24c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MosT common Neutral words\n",
    "top = Counter([item for sublist in Neutral_sent['temp_list'] for item in sublist])\n",
    "temp_neutral = pd.DataFrame(top.most_common(20))\n",
    "temp_neutral = temp_neutral.loc[1:,:]\n",
    "temp_neutral.columns = ['Common_words','count']\n",
    "temp_neutral.style.background_gradient(cmap='Reds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f05f3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = px.bar(temp_neutral, x=\"count\", y=\"Common_words\", title='Most Commmon Neutral Words', orientation='h', \n",
    "             width=700, height=700,color='Common_words')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050196aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.treemap(temp_neutral, path=['Common_words'], values='count',title='Tree Of Most Common Neutral Words')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d6fe5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = [word for word_list in train['temp_list1'] for word in word_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0ca398",
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_unique(entailment_judgment,numwords,raw_words):\n",
    "    '''\n",
    "    Input:\n",
    "        segment - Segment category (ex. 'Neutral');\n",
    "        numwords - how many specific words do you want to see in the final result; \n",
    "        raw_words - list  for item in train_data[train_data.segments == segments]['temp_list1']:\n",
    "    Output: \n",
    "        dataframe giving information about the name of the specific ingredient and how many times it occurs in the chosen cuisine (in descending order based on their counts)..\n",
    "\n",
    "    '''\n",
    "    allother = []\n",
    "    for item in train[train.entailment_judgment != entailment_judgment]['temp_list1']:\n",
    "        for word in item:\n",
    "            allother .append(word)\n",
    "    allother  = list(set(allother ))\n",
    "    \n",
    "    specificnonly = [x for x in raw_text if x not in allother]\n",
    "    \n",
    "    mycounter = Counter()\n",
    "    \n",
    "    for item in train[train.entailment_judgment == entailment_judgment]['temp_list1']:\n",
    "        for word in item:\n",
    "            mycounter[word] += 1\n",
    "    keep = list(specificnonly)\n",
    "    \n",
    "    for word in list(mycounter):\n",
    "        if word not in keep:\n",
    "            del mycounter[word]\n",
    "    \n",
    "    Unique_words = pd.DataFrame(mycounter.most_common(numwords), columns = ['words','count'])\n",
    "    \n",
    "    return Unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508a05ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "Unique_Positive= words_unique('ENTAILMENT', 20, raw_text)\n",
    "print(\"The top 20 unique words in Entailment Sentences are:\")\n",
    "Unique_Positive.style.background_gradient(cmap='Greens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde61b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.treemap(Unique_Positive, path=['words'], values='count',title='Tree Of Unique Positive Words')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c787d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from palettable.colorbrewer.qualitative import Pastel1_7\n",
    "plt.figure(figsize=(16,10))\n",
    "my_circle=plt.Circle((0,0), 0.7, color='white')\n",
    "plt.pie(Unique_Positive['count'], labels=Unique_Positive.words, colors=Pastel1_7.hex_colors)\n",
    "p=plt.gcf()\n",
    "p.gca().add_artist(my_circle)\n",
    "plt.title('DoNut Plot Of Unique Entailment Words')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9927f129",
   "metadata": {},
   "outputs": [],
   "source": [
    "Unique_Negative= words_unique('CONTRADICTION', 10, raw_text)\n",
    "print(\"The top 10 unique words in Contradicting Words are:\")\n",
    "Unique_Negative.style.background_gradient(cmap='Reds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14794d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from palettable.colorbrewer.qualitative import Pastel1_7\n",
    "plt.figure(figsize=(16,10))\n",
    "my_circle=plt.Circle((0,0), 0.7, color='white')\n",
    "plt.rcParams['text.color'] = 'black'\n",
    "plt.pie(Unique_Negative['count'], labels=Unique_Negative.words, colors=Pastel1_7.hex_colors)\n",
    "p=plt.gcf()\n",
    "p.gca().add_artist(my_circle)\n",
    "plt.title('DoNut Plot Of Unique Negative Words')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e416892d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Unique_Neutral= words_unique('NEUTRAL', 10, raw_text)\n",
    "print(\"The top 10 unique words in Neutral Tweets are:\")\n",
    "Unique_Neutral.style.background_gradient(cmap='Oranges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e36358",
   "metadata": {},
   "outputs": [],
   "source": [
    "from palettable.colorbrewer.qualitative import Pastel1_7\n",
    "plt.figure(figsize=(16,10))\n",
    "my_circle=plt.Circle((0,0), 0.7, color='white')\n",
    "plt.pie(Unique_Neutral['count'], labels=Unique_Neutral.words, colors=Pastel1_7.hex_colors)\n",
    "p=plt.gcf()\n",
    "p.gca().add_artist(my_circle)\n",
    "plt.title('DoNut Plot Of Unique Neutral Words')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fb0003",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv((r\"C:/Users/me1awq/PhD/docsim/datasets/open_source/SICK_train2.csv\"))\n",
    "df_test = pd.read_csv((r\"C:/Users/me1awq/PhD/docsim/datasets/open_source/SICK_train3.csv\"))\n",
    "df_submission = pd.read_csv((r\"C:/Users/me1awq/PhD/docsim/datasets/open_source/SICK_train4.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30d8395",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Num_words_text'] = df_train['sentence_A'].apply(lambda x:len(str(x).split())) #Number Of words in main Text in train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2b6e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[df_train['Num_words_text']>=3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103fd79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(output_dir, nlp, new_model_name):\n",
    "    ''' This Function Saves model to \n",
    "    given output directory'''\n",
    "    \n",
    "    output_dir = r'C:/Users/me1awq/PhD/docsim/train_results/'\n",
    "    if output_dir is not None:        \n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        nlp.meta[\"name\"] = new_model_name\n",
    "        nlp.to_disk(output_dir)\n",
    "        print(\"Saved model to\", output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7930486e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.training import Example\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train(train_data, output_dir, n_iter=20, model=None):\n",
    "    \"\"\"Load the model, set up the pipeline and train the entity recognizer.\"\"\"\n",
    "    if model is not None:\n",
    "        nlp = spacy.load(output_dir)  # load existing spaCy model\n",
    "        print(\"Loaded model '%s'\" % model)\n",
    "    else:\n",
    "        nlp = spacy.blank(\"en\")  # create blank Language class\n",
    "        print(\"Created blank 'en' model\")\n",
    "    \n",
    "    # create the built-in pipeline components and add them to the pipeline\n",
    "    # nlp.add_pipe works for built-ins that are registered with spaCy\n",
    "    if \"ner\" not in nlp.pipe_names:\n",
    "        ner = nlp.add_pipe(\"ner\", last=True)\n",
    "    # otherwise, get it so we can add labels\n",
    "    else:\n",
    "        ner = nlp.get_pipe(\"ner\")\n",
    "    \n",
    "    # add labels\n",
    "    for _, annotations in train_data:\n",
    "        for ent in annotations.get(\"entities\"):\n",
    "            ner.add_label(ent[2])\n",
    "\n",
    "    # get names of other pipes to disable them during training\n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n",
    "    \n",
    "    with nlp.disable_pipes(*other_pipes):  # only train NER\n",
    "        if model is None:\n",
    "            optimizer = nlp.begin_training()\n",
    "        else:\n",
    "            optimizer = nlp.resume_training()\n",
    "\n",
    "        # prepare the training data in the required format for spacy\n",
    "        examples = []\n",
    "        for text, annots in train_data:\n",
    "            examples.append(Example.from_dict(nlp.make_doc(text), annots))\n",
    "        \n",
    "        # train the model\n",
    "        for itn in tqdm(range(n_iter)):\n",
    "            random.shuffle(examples)\n",
    "            losses = {}\n",
    "            batches = spacy.util.minibatch(examples, size=spacy.util.compounding(4.0, 500.0, 1.001))\n",
    "            for batch in batches:\n",
    "                nlp.update(batch, sgd=optimizer, drop=0.5, losses=losses)\n",
    "            print(\"Losses\", losses)\n",
    "    \n",
    "    save_model(output_dir, nlp, 'st_ner')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801f2e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_out_path(entailment_judgment):\n",
    "    '''\n",
    "    Returns Model output path\n",
    "    '''\n",
    "    model_out_path = None\n",
    "    if entailment_judgment == 'ENTAILMENT':\n",
    "        model_out_path = r'C:/Users/me1awq/PhD/docsim/train_results/pos'\n",
    "    elif entailment_judgment == 'CONTRADICTION':\n",
    "        model_out_path = r'C:/Users/me1awq/PhD/docsim/train_results/neg'\n",
    "    return model_out_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2b6a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_data(entailment_judgment):\n",
    "    '''\n",
    "    Returns Trainong data in the format needed to train spacy NER\n",
    "    '''\n",
    "    train_data = []\n",
    "    for index, row in df_train.iterrows():\n",
    "        if row.entailment_judgment == entailment_judgment:\n",
    "            sentence_B = row.sentence_B\n",
    "            sentence_A = row.sentence_A\n",
    "            start = sentence_A.find(sentence_B)\n",
    "            end = start + len(sentence_B)\n",
    "            train_data.append((sentence_A, {\"entities\": [[start, end, 'sentence_B']]}))\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dbc94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = 'ENTAILMENT'\n",
    "\n",
    "train_data = get_training_data(sentiment)\n",
    "model_path = get_model_out_path(sentiment)\n",
    "# For DEmo Purposes I have taken 3 iterations you can train the model as you want\n",
    "train(train_data, model_path, n_iter=3, model=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26468550",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = 'CONTRADICTION'\n",
    "\n",
    "train_data = get_training_data(sentiment)\n",
    "model_path = get_model_out_path(sentiment)\n",
    "\n",
    "train(train_data, model_path, n_iter=3, model=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc8a8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_entities(sentence_A, model):\n",
    "    doc = model(sentence_A)\n",
    "    ent_array = []\n",
    "    for ent in doc.ents:\n",
    "        start = sentence_A.find(ent.sentence_A)\n",
    "        end = start + len(ent.sentence_A)\n",
    "        new_int = [start, end, ent.label_]\n",
    "        if new_int not in ent_array:\n",
    "            ent_array.append([start, end, ent.label_])\n",
    "    sentence_B = text[ent_array[0][0]: ent_array[0][1]] if len(ent_array) > 0 else text\n",
    "    return sentence_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf91769e",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_texts = []\n",
    "MODELS_BASE_PATH = r'C:/Users/me1awq/PhD/docsim/train_results/'\n",
    "\n",
    "if MODELS_BASE_PATH is not None:\n",
    "    print(\"Loading Models  from \", MODELS_BASE_PATH)\n",
    "    model_pos = spacy.load(MODELS_BASE_PATH + 'pos')\n",
    "    model_neg = spacy.load(MODELS_BASE_PATH + 'neg')\n",
    "        \n",
    "    for index, row in df_test.iterrows():\n",
    "        sentence_A = row.sentence_A\n",
    "        output_str = \"\"\n",
    "        if row.sentiment == 'NEUTRAL' or len(text.split()) <= 2:\n",
    "            selected_texts.append(sentence_A)\n",
    "        elif row.sentiment == 'ENTAILMENT':\n",
    "            selected_texts.append(predict_entities(sentence_A, model_pos))\n",
    "        else:\n",
    "            selected_texts.append(predict_entities(sentence_A, model_neg))\n",
    "        \n",
    "df_test['selected_text'] = selected_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529fa5e5",
   "metadata": {},
   "source": [
    "# Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003c40ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from bs4 import BeautifulSoup\n",
    "import re,string,unicodedata\n",
    "from keras.preprocessing import text, sequence\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from string import punctuation\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Embedding,LSTM,Dropout\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e150598",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.read_csv(r\"C:/Users/me1awq/PhD/docsim/datasets/open_source/sick.csv\", on_bad_lines='skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e896ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05eb4eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into two parts, with 70% of the data for training and 30% for testing\n",
    "train_data, test_data = train_test_split(full_df, test_size=0.3, random_state=42)\n",
    "\n",
    "# Split the training data into two parts, with 60% of the data for training and 40% for validation\n",
    "train_data, validation_data = train_test_split(train_data, test_size=0.4, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0733c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After running this code, you should have four variables: train_data, \n",
    "#validation_data, and test_data, which contain the corresponding splits \n",
    "#of your main dataset. You can use these variables to train, validate, \n",
    "#and test your machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4746af",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 10000\n",
    "maxlen = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c889815",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = text.Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(train_data)\n",
    "tokenized_train = tokenizer.texts_to_sequences(train_data)\n",
    "x_train = sequence.pad_sequences(tokenized_train, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995a93dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_test = tokenizer.texts_to_sequences(x_test)\n",
    "X_test = sequence.pad_sequences(tokenized_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4287c7a",
   "metadata": {},
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c55386",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining Neural Network\n",
    "model = Sequential()\n",
    "#Non-trainable embeddidng layer\n",
    "model.add(Embedding(max_features, output_dim=embed_size, weights=[embedding_matrix], input_length=maxlen, trainable=False))\n",
    "#LSTM \n",
    "model.add(LSTM(units=128 , return_sequences = True , recurrent_dropout = 0.25 , dropout = 0.25))\n",
    "model.add(LSTM(units=64 , recurrent_dropout = 0.1 , dropout = 0.1))\n",
    "model.add(Dense(units = 32 , activation = 'relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer=keras.optimizers.Adam(lr = 0.01), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daf226f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2912a065",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, batch_size = batch_size , validation_data = (X_test,y_test) , epochs = epochs , callbacks = [learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96887e6",
   "metadata": {},
   "source": [
    "# ANALYSIS AFTER TRAINING OF MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29768eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy of the model on Training Data is - \" , model.evaluate(x_train,y_train)[1]*100 , \"%\")\n",
    "print(\"Accuracy of the model on Testing Data is - \" , model.evaluate(X_test,y_test)[1]*100 , \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0a1add",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = [i for i in range(10)]\n",
    "fig , ax = plt.subplots(1,2)\n",
    "train_acc = history.history['accuracy']\n",
    "train_loss = history.history['loss']\n",
    "val_acc = history.history['val_accuracy']\n",
    "val_loss = history.history['val_loss']\n",
    "fig.set_size_inches(20,10)\n",
    "\n",
    "ax[0].plot(epochs , train_acc , 'go-' , label = 'Training Accuracy')\n",
    "ax[0].plot(epochs , val_acc , 'ro-' , label = 'Testing Accuracy')\n",
    "ax[0].set_title('Training & Testing Accuracy')\n",
    "ax[0].legend()\n",
    "ax[0].set_xlabel(\"Epochs\")\n",
    "ax[0].set_ylabel(\"Accuracy\")\n",
    "\n",
    "ax[1].plot(epochs , train_loss , 'go-' , label = 'Training Loss')\n",
    "ax[1].plot(epochs , val_loss , 'ro-' , label = 'Testing Loss')\n",
    "ax[1].set_title('Training & Testing Loss')\n",
    "ax[1].legend()\n",
    "ax[1].set_xlabel(\"Epochs\")\n",
    "ax[1].set_ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baee3806",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_classes(X_test)\n",
    "pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c151e16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred, target_names = ['Fake','Not Fake']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb994e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test,pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c73405",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = pd.DataFrame(cm , index = ['Fake','Original'] , columns = ['Fake','Original'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db84c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,10))\n",
    "sns.heatmap(cm,cmap= \"Blues\", linecolor = 'black' , linewidth = 1 , annot = True, fmt='' , xticklabels = ['Fake','Original'] , yticklabels = ['Fake','Original'])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebf0977",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8b95403",
   "metadata": {},
   "source": [
    "# Chat GPT code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d867df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertTokenizer\n",
    "import torch\n",
    "\n",
    "# Load the pre-trained BERT model and tokenizer\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "# Load the sick training data\n",
    "train_texts = [text for text, label in train_data]\n",
    "train_labels = [label for text, label in train_data]\n",
    "\n",
    "# Tokenize the texts\n",
    "train_input_ids = []\n",
    "train_attention_masks = []\n",
    "for text in train_texts:\n",
    "    encoded_dict = tokenizer.encode_plus(text, add_special_tokens=True, max_length=128, padding='max_length', truncation=True, return_attention_mask=True, return_tensors='pt')\n",
    "    train_input_ids.append(encoded_dict['input_ids'])\n",
    "    train_attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "train_input_ids = torch.cat(train_input_ids, dim=0)\n",
    "train_attention_masks = torch.cat(train_attention_masks, dim=0)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "\n",
    "# Define the optimizer and learning rate scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)\n",
    "\n",
    "# Train the model\n",
    "model.train()\n",
    "\n",
    "for epoch in range(3):\n",
    "    for step in range(len(train_data)):\n",
    "        input_ids = train_input_ids[step].unsqueeze(0)\n",
    "        attention_mask = train_attention_masks[step].unsqueeze(0)\n",
    "        labels = train_labels[step].unsqueeze(0)\n",
    "\n",
    "        model.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs[0]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "# Load the sick validation data\n",
    "val_texts = [text for text, label in val_data]\n",
    "val_labels = [label for text, label in val_data]\n",
    "\n",
    "# Tokenize the texts\n",
    "val_input_ids = []\n",
    "val_attention_masks = []\n",
    "for text in val_texts:\n",
    "    encoded_dict = tokenizer.encode_plus(text, add_special_tokens=True, max_length=128, padding='max_length', truncation=True, return_attention_mask=True, return_tensors='pt')\n",
    "    val_input_ids.append(encoded_dict['input_ids'])\n",
    "    val_attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "val_input_ids = torch.cat(val_input_ids, dim=0)\n",
    "val_attention_masks = torch.cat(val_attention_masks, dim=0)\n",
    "val_labels = torch.tensor(val_labels)\n",
    "\n",
    "# Evaluate the model on the validation data\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(val_input_ids, attention_mask=val_attention_masks)\n",
    "    logits = outputs[0]\n",
    "    preds = torch.argmax(logits, dim=1)\n",
    "    acc = torch.sum(preds == val_labels) / len(val_data)\n",
    "\n",
    "print(\"Validation accuracy: \", acc.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2903d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Load the pre-trained BERT model and tokenizer\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Define the training and validation data\n",
    "train_texts = [\"sick training text 1\", \"sick training text 2\", ...]\n",
    "train_labels = [0, 1, ...]\n",
    "val_texts = [\"sick validation text 1\", \"sick validation text 2\", ...]\n",
    "val_labels = [0, 1, ...]\n",
    "\n",
    "# Tokenize the texts\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True)\n",
    "\n",
    "# Convert the tokenized data into PyTorch tensors\n",
    "train_dataset = TensorDataset(torch.tensor(train_encodings['input_ids']), torch.tensor(train_encodings['attention_mask']), torch.tensor(train_labels))\n",
    "val_dataset = TensorDataset(torch.tensor(val_encodings['input_ids']), torch.tensor(val_encodings['attention_mask']), torch.tensor(val_labels))\n",
    "\n",
    "# Define the data loader for training and validation\n",
    "batch_size = 16\n",
    "train_dataloader = DataLoader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=batch_size)\n",
    "val_dataloader = DataLoader(val_dataset, sampler=SequentialSampler(val_dataset), batch_size=batch_size)\n",
    "\n",
    "# Define the optimizer and loss function\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Train the model\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch in train_dataloader:\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validate the model\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_preds = []\n",
    "    val_labels = []\n",
    "    for batch in val_dataloader:\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        loss = loss_fn(outputs.logits, labels)\n",
    "        val_loss += loss.item()\n",
    "        preds = torch.argmax(outputs.logits, dim=1).flatten()\n",
    "        val_preds.extend(preds.cpu().numpy())\n",
    "        val_labels.extend(labels.cpu().numpy())\n",
    "    val_f1 = f1_score(val_labels, val_preds)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss/len(train_dataloader)}, Validation Loss: {val_loss/len(val_dataloader)}, Validation F1 Score: {val_f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c418a7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

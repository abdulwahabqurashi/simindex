{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\me1awq\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing libraries\n",
    "#from numba import cuda\n",
    "import gensim\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import csv\n",
    "import re\n",
    "#import pandas as pd\n",
    "#from pandas import DataFrame\n",
    "#import pandas as pd\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/me1awq/PhD/docsim/datasets/rssb/Source rules or OCD rulebook.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Importing Source Rules or OCD Rulebook CSV file\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC:/Users/me1awq/PhD/docsim/datasets/rssb/Source rules or OCD rulebook.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file_object:\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m OCDline \u001b[38;5;129;01min\u001b[39;00m file_object:\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;28mprint\u001b[39m(OCDline)\n",
      "File \u001b[1;32m~\\.conda\\envs\\cpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    277\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m     )\n\u001b[1;32m--> 282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/me1awq/PhD/docsim/datasets/rssb/Source rules or OCD rulebook.csv'"
     ]
    }
   ],
   "source": [
    "# Importing Source Rules or OCD Rulebook CSV file\n",
    "\n",
    "with open ('C:/Users/me1awq/PhD/docsim/datasets/rssb/Source rules or OCD rulebook.csv') as file_object:\n",
    "    for OCDline in file_object:\n",
    "        print(OCDline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sentences tokenization of Source Rules or OCD Rulebook CSV file\n",
    "\n",
    "target_rules = []\n",
    "with open ('Source rules or OCD rulebook.csv') as file_object:\n",
    "    for trainline in file_object:\n",
    "        tokens_train = sent_tokenize(trainline)\n",
    "        target_rules.extend(tokens_train)\n",
    "\n",
    "    \n",
    "# Searching for text that includes any digits or decimal number. \"\\d\" is looking for digits in tokens\n",
    "\n",
    "withdigits_target_rules=[s for s in target_rules if re.findall(\"^\\d\",s)]\n",
    "print(withdigits_target_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Target Rules or EA Rulebook CSV file\n",
    "\n",
    "with open ('Target Rules or EA rulebook.csv') as file_object:\n",
    "    for EAline in file_object:\n",
    "        print(EAline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sentences tokenization of Target Rules or EA Rulebook CSV file\n",
    "\n",
    "source_rules = []\n",
    "with open ('Target Rules or EA rulebook.csv') as file_object:\n",
    "    for trainline in file_object:\n",
    "        tokens_train = sent_tokenize(trainline)\n",
    "        source_rules.extend(tokens_train)\n",
    "\n",
    "        \n",
    "# Searching for text that includes any digits or decimal number. \"\\d\" is looking for digits in tokens\n",
    "\n",
    "\n",
    "withdigits_source_rules=[s for s in source_rules if re.findall(\"^\\d\",s)]\n",
    "print(withdigits_source_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting Parameters for model\n",
    "\n",
    "class DocSim(object):\n",
    "    def __init__(self, w2v_model , stopwords=[]):\n",
    "        self.w2v_model = w2v_model\n",
    "        self.stopwords = stopwords\n",
    "\n",
    "    def vectorize(self, doc):\n",
    "        \"\"\"Identify the vector values for each word in the given document\"\"\"\n",
    "        doc = doc.lower()\n",
    "        words = [w for w in doc.split(\" \") if w not in self.stopwords]\n",
    "        word_vecs = []\n",
    "        for word in words:\n",
    "            try:\n",
    "                vec = self.w2v_model[word]\n",
    "                word_vecs.append(vec)\n",
    "            except KeyError:\n",
    "                # Ignore, if the word doesn't exist in the vocabulary\n",
    "                pass\n",
    "\n",
    "        # Assuming that document vector is the mean of all the word vectors\n",
    "\n",
    "        vector = np.mean(word_vecs, axis=0)\n",
    "        return vector\n",
    "\n",
    "\n",
    "    def _cosine_sim(self, vecA, vecB):\n",
    "        \"\"\"Find the cosine similarity distance between two vectors.\"\"\"\n",
    "        csim=( np.dot(vecA,vecB) )/ (np.linalg.norm(vecA)*np.linalg.norm(vecB))\n",
    "        if np.isnan(np.sum(csim)):\n",
    "            return 0\n",
    "        return csim\n",
    "\n",
    "    def calculate_similarity(self, withdigits_source_rules, withdigits_target_rules=[], threshold=0.8):\n",
    "        \"\"\"Calculates & returns similarity scores between given source rules & all\n",
    "        the target rules\"\"\"\n",
    "        if isinstance(withdigits_target_rules, str):\n",
    "            withdigits_target_rules = [withdigits_target_rules]\n",
    "\n",
    "\n",
    "        source_vec = self.vectorize(withdigits_source_rules)\n",
    "        results = []\n",
    "        \n",
    "        for rule in withdigits_target_rules:\n",
    "            target_vec = self.vectorize(rule)\n",
    "            sim_score = self._cosine_sim(source_vec, target_vec)\n",
    "            if sim_score > threshold:\n",
    "                results.append({\n",
    "                    'Cosine Sim Score':sim_score,\n",
    "                    'Target Rule':rule\n",
    "                })\n",
    "\n",
    "                \n",
    "            # Sort results by score in desc order\n",
    "            results.sort(key=lambda k : k['Cosine Sim Score'] , reverse=True)\n",
    "\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = DocSim(w2v_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the similarity score between a source rule & a target rule.\n",
    "\n",
    "\n",
    "if isinstance(withdigits_source_rules, str):\n",
    "    withdigits_source_rules = [withdigits_source_rules]\n",
    "   \n",
    "\n",
    "# This will return one target rules text with a similarity score\n",
    "\n",
    "for rule in withdigits_source_rules:\n",
    "    sim_scores= ds.calculate_similarity(rule, withdigits_target_rules)\n",
    "\n",
    "    \n",
    "    \n",
    "    # Source Rules are OCD Rules\n",
    "    # Target Rules are EA Rules\n",
    "    \n",
    "    # Printing the output in text file\n",
    "    \n",
    "    print(\"Source rule: {} \\n\\nSimilarity with Target Rule is \\n\\n {}\\n\".format(rule, sim_scores) , file=open(\"output.txt\", \"a\"))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    \n",
    "    # Printing output in Jupyter\n",
    "    \n",
    "    print(\"Source rule: {} \\n\\nSimilarity with Target Rule is \\n\\n {}\\n\".format(rule, sim_scores) )\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "FEQO4tDl7xH_"
   },
   "outputs": [],
   "source": [
    "display_architecture=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235,
     "referenced_widgets": [
      "311dd5614ff1456fa608b06c6a486333",
      "483e8e39248842cca6fdb69497417033",
      "898bb243539e4693a1a024e54dac42e2",
      "ab283be8197e4a638fd83dc475b57486",
      "af7cb58500024f7cac6545a44045bdd1",
      "d252ead0d3fc4885bed21c592dc9394c",
      "8ed15a3ae7c64fdea663832082e80529",
      "6a4014978e96442789889fef7919d87f",
      "173d4c16ef284a6085b183da2be8574e",
      "15d71a8c88ab4dc2bfb20853b5bac3d3",
      "fef9e2aa436040c0822605be0df0c359",
      "9b0393c7c87e42838da0e38fb72b2941",
      "3707cb9b877c451bb245d051c19af8fa",
      "28ac8f3a26ca4c51ab913c482234f3ab",
      "3ef057edd14f4fafbbb0b6fb81e9ba97",
      "8ff347600d6f42e5bf198232909fe086",
      "31a90525042744a49f8d48305354b9ec",
      "55811622761d49559291f3e74f072d31",
      "3c68af00a0784efca7a3dce29c060eef",
      "07acd3ae43eb4dfb893cc65e72320367",
      "4a1b68c322254a53a77e4d05e9ee7631",
      "e7c516f923f74666a8a4b11e17c333bd",
      "0be43a9c00324bb9abeedeb2a67b883a",
      "369a4af884f3436683d68ec126d7b6ec"
     ]
    },
    "id": "q8suV48O07TW",
    "outputId": "cb65b089-f9f1-423c-8c35-f5f39bc7c139"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import json \n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, T5Config\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-large')\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-large')\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q6zHDK7I1GsY",
    "outputId": "21dc9317-47da-414e-b6fb-a24f60e1cda6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5Config {\n",
      "  \"_name_or_path\": \"t5-large\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 4096,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 24,\n",
      "  \"num_heads\": 16,\n",
      "  \"num_layers\": 24,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if display_architecture==True:\n",
    " print(model.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5LaWN15NPIPC",
    "outputId": "623480ce-b408-462b-a8c5-5c12959f724c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5ForConditionalGeneration(\n",
      "  (shared): Embedding(32128, 1024)\n",
      "  (encoder): T5Stack(\n",
      "    (embed_tokens): Embedding(32128, 1024)\n",
      "    (block): ModuleList(\n",
      "      (0): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (relative_attention_bias): Embedding(32, 16)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (4): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (5): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (6): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (7): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (8): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (9): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (10): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (11): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (12): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (13): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (14): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (15): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (16): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (17): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (18): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (19): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (20): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (21): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (22): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (23): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): T5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (decoder): T5Stack(\n",
      "    (embed_tokens): Embedding(32128, 1024)\n",
      "    (block): ModuleList(\n",
      "      (0): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (relative_attention_bias): Embedding(32, 16)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (4): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (5): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (6): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (7): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (8): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (9): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (10): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (11): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (12): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (13): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (14): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (15): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (16): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (17): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (18): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (19): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (20): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (21): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (22): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (23): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): T5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=1024, out_features=32128, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "if(display_architecture==True):\n",
    "  print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DS2twf1P1UYI",
    "outputId": "e060a702-cf27-41b4-d162-ffb21872b81c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5Stack(\n",
      "  (embed_tokens): Embedding(32128, 1024)\n",
      "  (block): ModuleList(\n",
      "    (0): T5Block(\n",
      "      (layer): ModuleList(\n",
      "        (0): T5LayerSelfAttention(\n",
      "          (SelfAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (relative_attention_bias): Embedding(32, 16)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): T5LayerFF(\n",
      "          (DenseReluDense): T5DenseActDense(\n",
      "            (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "            (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (act): ReLU()\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): T5Block(\n",
      "      (layer): ModuleList(\n",
      "        (0): T5LayerSelfAttention(\n",
      "          (SelfAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): T5LayerFF(\n",
      "          (DenseReluDense): T5DenseActDense(\n",
      "            (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "            (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (act): ReLU()\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): T5Block(\n",
      "      (layer): ModuleList(\n",
      "        (0): T5LayerSelfAttention(\n",
      "          (SelfAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): T5LayerFF(\n",
      "          (DenseReluDense): T5DenseActDense(\n",
      "            (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "            (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (act): ReLU()\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): T5Block(\n",
      "      (layer): ModuleList(\n",
      "        (0): T5LayerSelfAttention(\n",
      "          (SelfAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): T5LayerFF(\n",
      "          (DenseReluDense): T5DenseActDense(\n",
      "            (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "            (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (act): ReLU()\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): T5Block(\n",
      "      (layer): ModuleList(\n",
      "        (0): T5LayerSelfAttention(\n",
      "          (SelfAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): T5LayerFF(\n",
      "          (DenseReluDense): T5DenseActDense(\n",
      "            (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "            (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (act): ReLU()\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): T5Block(\n",
      "      (layer): ModuleList(\n",
      "        (0): T5LayerSelfAttention(\n",
      "          (SelfAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): T5LayerFF(\n",
      "          (DenseReluDense): T5DenseActDense(\n",
      "            (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "            (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (act): ReLU()\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (6): T5Block(\n",
      "      (layer): ModuleList(\n",
      "        (0): T5LayerSelfAttention(\n",
      "          (SelfAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): T5LayerFF(\n",
      "          (DenseReluDense): T5DenseActDense(\n",
      "            (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "            (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (act): ReLU()\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (7): T5Block(\n",
      "      (layer): ModuleList(\n",
      "        (0): T5LayerSelfAttention(\n",
      "          (SelfAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): T5LayerFF(\n",
      "          (DenseReluDense): T5DenseActDense(\n",
      "            (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "            (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (act): ReLU()\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (8): T5Block(\n",
      "      (layer): ModuleList(\n",
      "        (0): T5LayerSelfAttention(\n",
      "          (SelfAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): T5LayerFF(\n",
      "          (DenseReluDense): T5DenseActDense(\n",
      "            (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "            (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (act): ReLU()\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (9): T5Block(\n",
      "      (layer): ModuleList(\n",
      "        (0): T5LayerSelfAttention(\n",
      "          (SelfAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): T5LayerFF(\n",
      "          (DenseReluDense): T5DenseActDense(\n",
      "            (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "            (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (act): ReLU()\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (10): T5Block(\n",
      "      (layer): ModuleList(\n",
      "        (0): T5LayerSelfAttention(\n",
      "          (SelfAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): T5LayerFF(\n",
      "          (DenseReluDense): T5DenseActDense(\n",
      "            (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "            (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (act): ReLU()\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (11): T5Block(\n",
      "      (layer): ModuleList(\n",
      "        (0): T5LayerSelfAttention(\n",
      "          (SelfAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): T5LayerFF(\n",
      "          (DenseReluDense): T5DenseActDense(\n",
      "            (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "            (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (act): ReLU()\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (12): T5Block(\n",
      "      (layer): ModuleList(\n",
      "        (0): T5LayerSelfAttention(\n",
      "          (SelfAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): T5LayerFF(\n",
      "          (DenseReluDense): T5DenseActDense(\n",
      "            (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "            (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (act): ReLU()\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (13): T5Block(\n",
      "      (layer): ModuleList(\n",
      "        (0): T5LayerSelfAttention(\n",
      "          (SelfAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): T5LayerFF(\n",
      "          (DenseReluDense): T5DenseActDense(\n",
      "            (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "            (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (act): ReLU()\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (14): T5Block(\n",
      "      (layer): ModuleList(\n",
      "        (0): T5LayerSelfAttention(\n",
      "          (SelfAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): T5LayerFF(\n",
      "          (DenseReluDense): T5DenseActDense(\n",
      "            (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "            (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (act): ReLU()\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (15): T5Block(\n",
      "      (layer): ModuleList(\n",
      "        (0): T5LayerSelfAttention(\n",
      "          (SelfAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): T5LayerFF(\n",
      "          (DenseReluDense): T5DenseActDense(\n",
      "            (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "            (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (act): ReLU()\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (16): T5Block(\n",
      "      (layer): ModuleList(\n",
      "        (0): T5LayerSelfAttention(\n",
      "          (SelfAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): T5LayerFF(\n",
      "          (DenseReluDense): T5DenseActDense(\n",
      "            (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "            (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (act): ReLU()\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (17): T5Block(\n",
      "      (layer): ModuleList(\n",
      "        (0): T5LayerSelfAttention(\n",
      "          (SelfAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): T5LayerFF(\n",
      "          (DenseReluDense): T5DenseActDense(\n",
      "            (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "            (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (act): ReLU()\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (18): T5Block(\n",
      "      (layer): ModuleList(\n",
      "        (0): T5LayerSelfAttention(\n",
      "          (SelfAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): T5LayerFF(\n",
      "          (DenseReluDense): T5DenseActDense(\n",
      "            (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "            (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (act): ReLU()\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (19): T5Block(\n",
      "      (layer): ModuleList(\n",
      "        (0): T5LayerSelfAttention(\n",
      "          (SelfAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): T5LayerFF(\n",
      "          (DenseReluDense): T5DenseActDense(\n",
      "            (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "            (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (act): ReLU()\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (20): T5Block(\n",
      "      (layer): ModuleList(\n",
      "        (0): T5LayerSelfAttention(\n",
      "          (SelfAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): T5LayerFF(\n",
      "          (DenseReluDense): T5DenseActDense(\n",
      "            (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "            (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (act): ReLU()\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (21): T5Block(\n",
      "      (layer): ModuleList(\n",
      "        (0): T5LayerSelfAttention(\n",
      "          (SelfAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): T5LayerFF(\n",
      "          (DenseReluDense): T5DenseActDense(\n",
      "            (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "            (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (act): ReLU()\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (22): T5Block(\n",
      "      (layer): ModuleList(\n",
      "        (0): T5LayerSelfAttention(\n",
      "          (SelfAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): T5LayerFF(\n",
      "          (DenseReluDense): T5DenseActDense(\n",
      "            (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "            (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (act): ReLU()\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (23): T5Block(\n",
      "      (layer): ModuleList(\n",
      "        (0): T5LayerSelfAttention(\n",
      "          (SelfAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): T5LayerFF(\n",
      "          (DenseReluDense): T5DenseActDense(\n",
      "            (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "            (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (act): ReLU()\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (final_layer_norm): T5LayerNorm()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "if display_architecture==True:\n",
    "  print(model.encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MCwdhX9U1MA5",
    "outputId": "ae39b023-77ec-483d-fb33-2bc59d2c0996"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5Stack(\n",
      "  (embed_tokens): Embedding(32128, 1024)\n",
      "  (block): ModuleList(\n",
      "    (0): T5Block(\n",
      "      (layer): ModuleList(\n",
      "        (0): T5LayerSelfAttention(\n",
      "          (SelfAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (relative_attention_bias): Embedding(32, 16)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): T5LayerCrossAttention(\n",
      "          (EncDecAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (2): T5LayerFF(\n",
      "          (DenseReluDense): T5DenseActDense(\n",
      "            (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "            (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (act): ReLU()\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): T5Block(\n",
      "      (layer): ModuleList(\n",
      "        (0): T5LayerSelfAttention(\n",
      "          (SelfAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): T5LayerCrossAttention(\n",
      "          (EncDecAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (2): T5LayerFF(\n",
      "          (DenseReluDense): T5DenseActDense(\n",
      "            (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "            (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (act): ReLU()\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): T5Block(\n",
      "      (layer): ModuleList(\n",
      "        (0): T5LayerSelfAttention(\n",
      "          (SelfAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): T5LayerCrossAttention(\n",
      "          (EncDecAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (2): T5LayerFF(\n",
      "          (DenseReluDense): T5DenseActDense(\n",
      "            (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "            (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (act): ReLU()\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): T5Block(\n",
      "      (layer): ModuleList(\n",
      "        (0): T5LayerSelfAttention(\n",
      "          (SelfAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): T5LayerCrossAttention(\n",
      "          (EncDecAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (2): T5LayerFF(\n",
      "          (DenseReluDense): T5DenseActDense(\n",
      "            (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "            (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (act): ReLU()\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): T5Block(\n",
      "      (layer): ModuleList(\n",
      "        (0): T5LayerSelfAttention(\n",
      "          (SelfAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): T5LayerCrossAttention(\n",
      "          (EncDecAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (2): T5LayerFF(\n",
      "          (DenseReluDense): T5DenseActDense(\n",
      "            (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "            (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (act): ReLU()\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): T5Block(\n",
      "      (layer): ModuleList(\n",
      "        (0): T5LayerSelfAttention(\n",
      "          (SelfAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): T5LayerCrossAttention(\n",
      "          (EncDecAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (2): T5LayerFF(\n",
      "          (DenseReluDense): T5DenseActDense(\n",
      "            (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "            (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (act): ReLU()\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (6): T5Block(\n",
      "      (layer): ModuleList(\n",
      "        (0): T5LayerSelfAttention(\n",
      "          (SelfAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): T5LayerCrossAttention(\n",
      "          (EncDecAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (2): T5LayerFF(\n",
      "          (DenseReluDense): T5DenseActDense(\n",
      "            (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "            (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (act): ReLU()\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (7): T5Block(\n",
      "      (layer): ModuleList(\n",
      "        (0): T5LayerSelfAttention(\n",
      "          (SelfAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): T5LayerCrossAttention(\n",
      "          (EncDecAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (2): T5LayerFF(\n",
      "          (DenseReluDense): T5DenseActDense(\n",
      "            (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "            (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (act): ReLU()\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (8): T5Block(\n",
      "      (layer): ModuleList(\n",
      "        (0): T5LayerSelfAttention(\n",
      "          (SelfAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): T5LayerCrossAttention(\n",
      "          (EncDecAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (2): T5LayerFF(\n",
      "          (DenseReluDense): T5DenseActDense(\n",
      "            (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "            (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (act): ReLU()\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (9): T5Block(\n",
      "      (layer): ModuleList(\n",
      "        (0): T5LayerSelfAttention(\n",
      "          (SelfAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): T5LayerCrossAttention(\n",
      "          (EncDecAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (2): T5LayerFF(\n",
      "          (DenseReluDense): T5DenseActDense(\n",
      "            (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "            (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (act): ReLU()\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (10): T5Block(\n",
      "      (layer): ModuleList(\n",
      "        (0): T5LayerSelfAttention(\n",
      "          (SelfAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): T5LayerCrossAttention(\n",
      "          (EncDecAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (2): T5LayerFF(\n",
      "          (DenseReluDense): T5DenseActDense(\n",
      "            (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "            (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (act): ReLU()\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (11): T5Block(\n",
      "      (layer): ModuleList(\n",
      "        (0): T5LayerSelfAttention(\n",
      "          (SelfAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): T5LayerCrossAttention(\n",
      "          (EncDecAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (2): T5LayerFF(\n",
      "          (DenseReluDense): T5DenseActDense(\n",
      "            (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "            (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (act): ReLU()\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (12): T5Block(\n",
      "      (layer): ModuleList(\n",
      "        (0): T5LayerSelfAttention(\n",
      "          (SelfAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): T5LayerCrossAttention(\n",
      "          (EncDecAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (2): T5LayerFF(\n",
      "          (DenseReluDense): T5DenseActDense(\n",
      "            (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "            (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (act): ReLU()\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (13): T5Block(\n",
      "      (layer): ModuleList(\n",
      "        (0): T5LayerSelfAttention(\n",
      "          (SelfAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): T5LayerCrossAttention(\n",
      "          (EncDecAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (2): T5LayerFF(\n",
      "          (DenseReluDense): T5DenseActDense(\n",
      "            (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "            (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (act): ReLU()\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (14): T5Block(\n",
      "      (layer): ModuleList(\n",
      "        (0): T5LayerSelfAttention(\n",
      "          (SelfAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): T5LayerCrossAttention(\n",
      "          (EncDecAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (2): T5LayerFF(\n",
      "          (DenseReluDense): T5DenseActDense(\n",
      "            (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "            (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (act): ReLU()\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (15): T5Block(\n",
      "      (layer): ModuleList(\n",
      "        (0): T5LayerSelfAttention(\n",
      "          (SelfAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): T5LayerCrossAttention(\n",
      "          (EncDecAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (2): T5LayerFF(\n",
      "          (DenseReluDense): T5DenseActDense(\n",
      "            (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "            (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (act): ReLU()\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (16): T5Block(\n",
      "      (layer): ModuleList(\n",
      "        (0): T5LayerSelfAttention(\n",
      "          (SelfAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): T5LayerCrossAttention(\n",
      "          (EncDecAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (2): T5LayerFF(\n",
      "          (DenseReluDense): T5DenseActDense(\n",
      "            (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "            (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (act): ReLU()\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (17): T5Block(\n",
      "      (layer): ModuleList(\n",
      "        (0): T5LayerSelfAttention(\n",
      "          (SelfAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): T5LayerCrossAttention(\n",
      "          (EncDecAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (2): T5LayerFF(\n",
      "          (DenseReluDense): T5DenseActDense(\n",
      "            (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "            (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (act): ReLU()\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (18): T5Block(\n",
      "      (layer): ModuleList(\n",
      "        (0): T5LayerSelfAttention(\n",
      "          (SelfAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): T5LayerCrossAttention(\n",
      "          (EncDecAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (2): T5LayerFF(\n",
      "          (DenseReluDense): T5DenseActDense(\n",
      "            (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "            (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (act): ReLU()\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (19): T5Block(\n",
      "      (layer): ModuleList(\n",
      "        (0): T5LayerSelfAttention(\n",
      "          (SelfAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): T5LayerCrossAttention(\n",
      "          (EncDecAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (2): T5LayerFF(\n",
      "          (DenseReluDense): T5DenseActDense(\n",
      "            (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "            (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (act): ReLU()\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (20): T5Block(\n",
      "      (layer): ModuleList(\n",
      "        (0): T5LayerSelfAttention(\n",
      "          (SelfAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): T5LayerCrossAttention(\n",
      "          (EncDecAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (2): T5LayerFF(\n",
      "          (DenseReluDense): T5DenseActDense(\n",
      "            (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "            (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (act): ReLU()\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (21): T5Block(\n",
      "      (layer): ModuleList(\n",
      "        (0): T5LayerSelfAttention(\n",
      "          (SelfAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): T5LayerCrossAttention(\n",
      "          (EncDecAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (2): T5LayerFF(\n",
      "          (DenseReluDense): T5DenseActDense(\n",
      "            (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "            (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (act): ReLU()\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (22): T5Block(\n",
      "      (layer): ModuleList(\n",
      "        (0): T5LayerSelfAttention(\n",
      "          (SelfAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): T5LayerCrossAttention(\n",
      "          (EncDecAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (2): T5LayerFF(\n",
      "          (DenseReluDense): T5DenseActDense(\n",
      "            (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "            (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (act): ReLU()\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (23): T5Block(\n",
      "      (layer): ModuleList(\n",
      "        (0): T5LayerSelfAttention(\n",
      "          (SelfAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): T5LayerCrossAttention(\n",
      "          (EncDecAttention): T5Attention(\n",
      "            (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (2): T5LayerFF(\n",
      "          (DenseReluDense): T5DenseActDense(\n",
      "            (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "            (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (act): ReLU()\n",
      "          )\n",
      "          (layer_norm): T5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (final_layer_norm): T5LayerNorm()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "if display_architecture==True:\n",
    "  print(model.decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GmrCDtcL1hPn",
    "outputId": "d93ba363-7336-4514-b693-b4c33dd8cb07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method T5ForConditionalGeneration.forward of T5ForConditionalGeneration(\n",
      "  (shared): Embedding(32128, 1024)\n",
      "  (encoder): T5Stack(\n",
      "    (embed_tokens): Embedding(32128, 1024)\n",
      "    (block): ModuleList(\n",
      "      (0): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (relative_attention_bias): Embedding(32, 16)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (4): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (5): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (6): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (7): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (8): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (9): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (10): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (11): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (12): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (13): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (14): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (15): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (16): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (17): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (18): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (19): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (20): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (21): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (22): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (23): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): T5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (decoder): T5Stack(\n",
      "    (embed_tokens): Embedding(32128, 1024)\n",
      "    (block): ModuleList(\n",
      "      (0): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (relative_attention_bias): Embedding(32, 16)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (4): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (5): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (6): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (7): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (8): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (9): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (10): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (11): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (12): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (13): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (14): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (15): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (16): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (17): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (18): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (19): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (20): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (21): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (22): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (23): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): T5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=1024, out_features=32128, bias=False)\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "if display_architecture==True:\n",
    "  print(model.forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "S5KfhCrifP01"
   },
   "outputs": [],
   "source": [
    "def summarize(input_text,min_len):\n",
    "    \n",
    "    clean_text = input_text.strip().replace(\"\\n\",\"\")\n",
    "    # calculate the number of character for input rule/clause\n",
    "    print('\\033[1m' + 'Input rule/caluse for text summarization:' + '\\033[0m')\n",
    "    print (clean_text)\n",
    "    print (\"\\n\")\n",
    "    print('\\033[1m' + 'Number of characters in the input rule/clause:' + '\\033[0m')\n",
    "    print (len(input_text)) \n",
    "  \n",
    "    tokenized_input_text = tokenizer.encode(clean_text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    # summmarize \n",
    "    summary_ids = model.generate(tokenized_input_text,\n",
    "                                    num_beams=4,\n",
    "                                    no_repeat_ngram_size=2,\n",
    "                                    min_length=30,\n",
    "                                    max_length=min_len,\n",
    "                                    early_stopping=True)\n",
    "\n",
    "    output_text = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vqiTNoDc7pOv",
    "outputId": "d46bc587-b39d-4e8e-bd5e-3d4d6d529168"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mInput rule/caluse for text summarization:\u001b[0m\n",
      "2.1.3.2 the rules must provide for: a) the full range of foreseeablefailure conditions, from simple to complex, and their consequences forthe functionality of the system as a whole and its ability to maintaina safe interval between trains b) establishing a clear understandingbetween signallers and train drivers about movements to be made andprecautions to be taken during the movement to reduce the likelihoodof collision c) protocols for spoken communications between signallerand train drivers and any intermediaries involved in the passing ofinformation.\n",
      "\n",
      "\n",
      "\u001b[1mNumber of characters in the input rule/clause:\u001b[0m\n",
      "569\n",
      "\u001b[1m\n",
      "\n",
      "Summarized rules/clauses: \n",
      "\u001b[0m\n",
      ". 2.1.3.3 the rules must provide for: 2.2.3.1 2.1.3. The rules should provide: a) the full range of foreseeable failure conditions, from simple to complex, and their consequences for the\n",
      "\u001b[1m\n",
      " Number of characters in the summarized rules/clauses:\u001b[0m\n",
      "186\n"
     ]
    }
   ],
   "source": [
    "# input the text for summarization\n",
    "input_text=\"\"\"\n",
    "2.1.3.2 the rules must provide for: a) the full range of foreseeable\n",
    "failure conditions, from simple to complex, and their consequences for\n",
    "the functionality of the system as a whole and its ability to maintain\n",
    "a safe interval between trains b) establishing a clear understanding\n",
    "between signallers and train drivers about movements to be made and\n",
    "precautions to be taken during the movement to reduce the likelihood\n",
    "of collision c) protocols for spoken communications between signaller\n",
    "and train drivers and any intermediaries involved in the passing of\n",
    "information.\n",
    "\"\"\"\n",
    "\n",
    "# summarize the output\n",
    "summarized_output=summarize(input_text,50)\n",
    "\n",
    "# printing the summarize the output\n",
    "print('\\033[1m' + '\\n\\nSummarized rules/clauses: \\n' + '\\033[0m')\n",
    "print (summarized_output)\n",
    "\n",
    "# calculate the number of character for input rule/clause\n",
    "print('\\033[1m' + '\\n Number of characters in the summarized rules/clauses:' + '\\033[0m')\n",
    "print(len(summarized_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2321zS1Q3jPX",
    "outputId": "fccf0c6e-926f-4f65-b3ba-b0e19715f87b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mInput rule/caluse for text summarization:\u001b[0m\n",
      "2.1.3.2 the rules must provide for: a) the full range of foreseeablefailure conditions, from simple to complex, and their consequences forthe functionality of the system as a whole and its ability to maintaina safe interval between trains b) establishing a clear understandingbetween signallers and train drivers about movements to be made andprecautions to be taken during the movement to reduce the likelihoodof collision c) protocols for spoken communications between signallerand train drivers and any intermediaries involved in the passing ofinformation.\n",
      "\n",
      "\n",
      "\u001b[1mNumber of characters in the input rule/clause:\u001b[0m\n",
      "569\n",
      "\u001b[1m\n",
      "\n",
      "Summarized rules/clauses: \n",
      "\u001b[0m\n",
      ". 2.1.3.3 the rules must provide for: 2.2.3.1 2.1.3. The rules should provide: a) the full range of foreseeable failure conditions, from simple to complex, and their consequences for the\n",
      "\u001b[1m\n",
      " Number of characters in the summarized rules/clauses:\u001b[0m\n",
      "186\n"
     ]
    }
   ],
   "source": [
    "text =\"\"\"2.4.2.4 Operating rules must specify temporary controls \n",
    "to be applied to train movements when: a) a visual examination of the \n",
    "site has not revealed a hazard, following a report of an infrastructure\n",
    "defect b) a hazard has been assessed as presenting a sufficiently low \n",
    "risk to the safety of trains to permit movements to resume, but work \n",
    "is required to eliminate the hazard  c) the hazard has been found to \n",
    "be a malfunction of signalling equipment (requirements for authorising\n",
    "train movements when the signalling system cannot be used because of \n",
    "defects are described in section 2.2 of this operational concept document)\n",
    "d) a line is affected by floodwater or snow e) there are exceptional \n",
    "rail head conditions.\n",
    "\"\"\"\n",
    "\n",
    "# summarize the output\n",
    "summarized_output=summarize(input_text,50)\n",
    "\n",
    "# printing the summarize the output\n",
    "print('\\033[1m' + '\\n\\nSummarized rules/clauses: \\n' + '\\033[0m')\n",
    "print (summarized_output)\n",
    "\n",
    "# calculate the number of character for input rule/clause\n",
    "print('\\033[1m' + '\\n Number of characters in the summarized rules/clauses:' + '\\033[0m')\n",
    "print(len(summarized_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k_h8oQ55_zr5",
    "outputId": "7c957d5a-6711-4169-9244-51562a6cc9cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mInput rule/caluse for text summarization:\u001b[0m\n",
      "2.1.3.2 the rules must provide for: a) the full range of foreseeablefailure conditions, from simple to complex, and their consequences forthe functionality of the system as a whole and its ability to maintaina safe interval between trains b) establishing a clear understandingbetween signallers and train drivers about movements to be made andprecautions to be taken during the movement to reduce the likelihoodof collision c) protocols for spoken communications between signallerand train drivers and any intermediaries involved in the passing ofinformation.\n",
      "\n",
      "\n",
      "\u001b[1mNumber of characters in the input rule/clause:\u001b[0m\n",
      "569\n",
      "\u001b[1m\n",
      "\n",
      "Summarized rules/clauses: \n",
      "\u001b[0m\n",
      ". 2.1.3.3 the rules must provide for: 2.2.3.1 2.1.3. The rules should provide: a) the full range of foreseeable failure conditions, from simple to complex, and their consequences for the\n",
      "\u001b[1m\n",
      " Number of characters in the summarized rules/clauses:\u001b[0m\n",
      "186\n"
     ]
    }
   ],
   "source": [
    "text =\"\"\" 2.5.3.1 General requirements for the loading and preparation\n",
    "of freight trains must be defined in operating rules.  Operating instructions,\n",
    "appropriate to the type of traffic and wagons they deal with, must be provided\n",
    "to people responsible for the loading and preparation of freight trains \n",
    "covering: a) securing a load to prevent it from moving around or falling \n",
    "from a wagon during transit b) distributing the load evenly on each wagon \n",
    "c) accessing or identifying and recording information about the wagon and \n",
    "its load required for safe train formation and movement   d) ensuring the \n",
    "train has sufficient braking capacity e) identifying and labelling dangerous\n",
    "goods f) the separation of incompatible dangerous goods g) obtaining confirmation\n",
    "that wagons containing dangerous goods have been securely closed  h) safety\n",
    "checks and documentation prior to departure i) the dispatch of freight trains.\n",
    "\"\"\"\n",
    "\n",
    "# summarize the output\n",
    "summarized_output=summarize(input_text,50)\n",
    "\n",
    "# printing the summarize the output\n",
    "print('\\033[1m' + '\\n\\nSummarized rules/clauses: \\n' + '\\033[0m')\n",
    "print (summarized_output)\n",
    "\n",
    "# calculate the number of character for input rule/clause\n",
    "print('\\033[1m' + '\\n Number of characters in the summarized rules/clauses:' + '\\033[0m')\n",
    "print(len(summarized_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mInput rule/caluse for text summarization:\u001b[0m\n",
      "2.1.3.2 the rules must provide for: a) the full range of foreseeablefailure conditions, from simple to complex, and their consequences forthe functionality of the system as a whole and its ability to maintaina safe interval between trains b) establishing a clear understandingbetween signallers and train drivers about movements to be made andprecautions to be taken during the movement to reduce the likelihoodof collision c) protocols for spoken communications between signallerand train drivers and any intermediaries involved in the passing ofinformation.\n",
      "\n",
      "\n",
      "\u001b[1mNumber of characters in the input rule/clause:\u001b[0m\n",
      "569\n",
      "\u001b[1m\n",
      "\n",
      "Summarized rules/clauses: \n",
      "\u001b[0m\n",
      ". 2.1.3.3 the rules must provide for: 2.2.3.1 2.1.3. The rules should provide: a) the full range of foreseeable failure conditions, from simple to complex, and their consequences for the\n",
      "\u001b[1m\n",
      " Number of characters in the summarized rules/clauses:\u001b[0m\n",
      "186\n"
     ]
    }
   ],
   "source": [
    "text =\"\"\" 2.5.3.6 Freight train drivers must be provided with the \n",
    "following information before starting a journey. a) The formation of their \n",
    "train, including its brake force, weight and length. b) The lowest maximum \n",
    "permitted speed of any vehicle in the train. c) The route availability of \n",
    "the vehicles in the train. d) Details of any dangerous goods being conveyed.\n",
    "e) Special conditions applicable to the movement of any load or vehicle \n",
    "being conveyed. f) Vehicles in the train which have defects requiring a \n",
    "reduction in speed of the train. g) Vehicles in the train without operative\n",
    "automatic brakes.  The information must be updated when the formation is \n",
    "changed or the status of vehicles is changed (for example, loaded to empty).\n",
    "\"\"\"\n",
    "\n",
    "# summarize the output\n",
    "summarized_output=summarize(input_text,50)\n",
    "\n",
    "# printing the summarize the output\n",
    "print('\\033[1m' + '\\n\\nSummarized rules/clauses: \\n' + '\\033[0m')\n",
    "print (summarized_output)\n",
    "\n",
    "# calculate the number of character for input rule/clause\n",
    "print('\\033[1m' + '\\n Number of characters in the summarized rules/clauses:' + '\\033[0m')\n",
    "print(len(summarized_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mInput rule/caluse for text summarization:\u001b[0m\n",
      "2.1.3.2 the rules must provide for: a) the full range of foreseeablefailure conditions, from simple to complex, and their consequences forthe functionality of the system as a whole and its ability to maintaina safe interval between trains b) establishing a clear understandingbetween signallers and train drivers about movements to be made andprecautions to be taken during the movement to reduce the likelihoodof collision c) protocols for spoken communications between signallerand train drivers and any intermediaries involved in the passing ofinformation.\n",
      "\n",
      "\n",
      "\u001b[1mNumber of characters in the input rule/clause:\u001b[0m\n",
      "569\n",
      "\u001b[1m\n",
      "\n",
      "Summarized rules/clauses: \n",
      "\u001b[0m\n",
      ". 2.1.3.3 the rules must provide for: 2.2.3.1 2.1.3. The rules should provide: a) the full range of foreseeable failure conditions, from simple to complex, and their consequences for the\n",
      "\u001b[1m\n",
      " Number of characters in the summarized rules/clauses:\u001b[0m\n",
      "186\n"
     ]
    }
   ],
   "source": [
    "text =\"\"\" 2.9.2.3 Operating rules for work on the infrastructure of \n",
    "electrified lines, including the electrification equipment, must: a) \n",
    "define the responsibilities for planning, establishing and maintaining \n",
    "a safe system of work, including control of the electric current supply \n",
    "and obtaining an isolation b) define the procedure for obtaining an \n",
    "isolation of electrical equipment and securing the isolated section \n",
    "against accidental charging with electricity c) specify any distance \n",
    "from electrical equipment required to assess whether work can be carried\n",
    "out safely without an isolation d) identify and describe the safety \n",
    "equipment required to protect workers from electric shock, the type \n",
    "of work which they can do safely and limitations on the tools, plant \n",
    "and equipment which they can use without obtaining an isolation. \n",
    "\"\"\"\n",
    "\n",
    "# summarize the output\n",
    "summarized_output=summarize(input_text,50)\n",
    "\n",
    "# printing the summarize the output\n",
    "print('\\033[1m' + '\\n\\nSummarized rules/clauses: \\n' + '\\033[0m')\n",
    "print (summarized_output)\n",
    "\n",
    "# calculate the number of character for input rule/clause\n",
    "print('\\033[1m' + '\\n Number of characters in the summarized rules/clauses:' + '\\033[0m')\n",
    "print(len(summarized_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mInput rule/caluse for text summarization:\u001b[0m\n",
      "2.1.3.2 the rules must provide for: a) the full range of foreseeablefailure conditions, from simple to complex, and their consequences forthe functionality of the system as a whole and its ability to maintaina safe interval between trains b) establishing a clear understandingbetween signallers and train drivers about movements to be made andprecautions to be taken during the movement to reduce the likelihoodof collision c) protocols for spoken communications between signallerand train drivers and any intermediaries involved in the passing ofinformation.\n",
      "\n",
      "\n",
      "\u001b[1mNumber of characters in the input rule/clause:\u001b[0m\n",
      "569\n",
      "\u001b[1m\n",
      "\n",
      "Summarized rules/clauses: \n",
      "\u001b[0m\n",
      ". 2.1.3.3 the rules must provide for: 2.2.3.1 2.1.3. The rules should provide: a) the full range of foreseeable failure conditions, from simple to complex, and their consequences for the\n",
      "\u001b[1m\n",
      " Number of characters in the summarized rules/clauses:\u001b[0m\n",
      "186\n"
     ]
    }
   ],
   "source": [
    "text =\"\"\" 2.9.2.1 Differences between electrification \n",
    "systems, their technical and physical characteristics and \n",
    "impact on workforce safety, must be addressed in system-specific instructions.\n",
    "\"\"\"\n",
    "\n",
    "# summarize the output\n",
    "summarized_output=summarize(input_text,50)\n",
    "\n",
    "# printing the summarize the output\n",
    "print('\\033[1m' + '\\n\\nSummarized rules/clauses: \\n' + '\\033[0m')\n",
    "print (summarized_output)\n",
    "\n",
    "# calculate the number of character for input rule/clause\n",
    "print('\\033[1m' + '\\n Number of characters in the summarized rules/clauses:' + '\\033[0m')\n",
    "print(len(summarized_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mInput rule/caluse for text summarization:\u001b[0m\n",
      "2.1.3.2 the rules must provide for: a) the full range of foreseeablefailure conditions, from simple to complex, and their consequences forthe functionality of the system as a whole and its ability to maintaina safe interval between trains b) establishing a clear understandingbetween signallers and train drivers about movements to be made andprecautions to be taken during the movement to reduce the likelihoodof collision c) protocols for spoken communications between signallerand train drivers and any intermediaries involved in the passing ofinformation.\n",
      "\n",
      "\n",
      "\u001b[1mNumber of characters in the input rule/clause:\u001b[0m\n",
      "569\n",
      "\u001b[1m\n",
      "\n",
      "Summarized rules/clauses: \n",
      "\u001b[0m\n",
      ". 2.1.3.3 the rules must provide for: 2.2.3.1 2.1.3. The rules should provide: a) the full range of foreseeable failure conditions, from simple to complex, and their consequences for the\n",
      "\u001b[1m\n",
      " Number of characters in the summarized rules/clauses:\u001b[0m\n",
      "186\n"
     ]
    }
   ],
   "source": [
    "text =\"\"\" 2.8.10.1 Operating rules must outline the \n",
    "actions to be taken by station and train operating staff, \n",
    "to prevent people using stations from being injured by \n",
    "moving trains or during boarding and alighting.  \n",
    "\"\"\"\n",
    "\n",
    "# summarize the output\n",
    "summarized_output=summarize(input_text,50)\n",
    "\n",
    "# printing the summarize the output\n",
    "print('\\033[1m' + '\\n\\nSummarized rules/clauses: \\n' + '\\033[0m')\n",
    "print (summarized_output)\n",
    "\n",
    "# calculate the number of character for input rule/clause\n",
    "print('\\033[1m' + '\\n Number of characters in the summarized rules/clauses:' + '\\033[0m')\n",
    "print(len(summarized_output))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Summarizing_Text_with_T5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "07acd3ae43eb4dfb893cc65e72320367": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_369a4af884f3436683d68ec126d7b6ec",
      "placeholder": "​",
      "style": "IPY_MODEL_0be43a9c00324bb9abeedeb2a67b883a",
      "value": " 792k/792k [00:00&lt;00:00, 1.68MB/s]"
     }
    },
    "0be43a9c00324bb9abeedeb2a67b883a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "15d71a8c88ab4dc2bfb20853b5bac3d3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "173d4c16ef284a6085b183da2be8574e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fef9e2aa436040c0822605be0df0c359",
       "IPY_MODEL_9b0393c7c87e42838da0e38fb72b2941"
      ],
      "layout": "IPY_MODEL_15d71a8c88ab4dc2bfb20853b5bac3d3"
     }
    },
    "28ac8f3a26ca4c51ab913c482234f3ab": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "311dd5614ff1456fa608b06c6a486333": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_898bb243539e4693a1a024e54dac42e2",
       "IPY_MODEL_ab283be8197e4a638fd83dc475b57486"
      ],
      "layout": "IPY_MODEL_483e8e39248842cca6fdb69497417033"
     }
    },
    "31a90525042744a49f8d48305354b9ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3c68af00a0784efca7a3dce29c060eef",
       "IPY_MODEL_07acd3ae43eb4dfb893cc65e72320367"
      ],
      "layout": "IPY_MODEL_55811622761d49559291f3e74f072d31"
     }
    },
    "369a4af884f3436683d68ec126d7b6ec": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3707cb9b877c451bb245d051c19af8fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "3c68af00a0784efca7a3dce29c060eef": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e7c516f923f74666a8a4b11e17c333bd",
      "max": 791656,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4a1b68c322254a53a77e4d05e9ee7631",
      "value": 791656
     }
    },
    "3ef057edd14f4fafbbb0b6fb81e9ba97": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "483e8e39248842cca6fdb69497417033": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4a1b68c322254a53a77e4d05e9ee7631": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "55811622761d49559291f3e74f072d31": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6a4014978e96442789889fef7919d87f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "898bb243539e4693a1a024e54dac42e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d252ead0d3fc4885bed21c592dc9394c",
      "max": 1200,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_af7cb58500024f7cac6545a44045bdd1",
      "value": 1200
     }
    },
    "8ed15a3ae7c64fdea663832082e80529": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8ff347600d6f42e5bf198232909fe086": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9b0393c7c87e42838da0e38fb72b2941": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8ff347600d6f42e5bf198232909fe086",
      "placeholder": "​",
      "style": "IPY_MODEL_3ef057edd14f4fafbbb0b6fb81e9ba97",
      "value": " 2.95G/2.95G [03:27&lt;00:00, 14.2MB/s]"
     }
    },
    "ab283be8197e4a638fd83dc475b57486": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6a4014978e96442789889fef7919d87f",
      "placeholder": "​",
      "style": "IPY_MODEL_8ed15a3ae7c64fdea663832082e80529",
      "value": " 1.20k/1.20k [03:27&lt;00:00, 5.78B/s]"
     }
    },
    "af7cb58500024f7cac6545a44045bdd1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "d252ead0d3fc4885bed21c592dc9394c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e7c516f923f74666a8a4b11e17c333bd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fef9e2aa436040c0822605be0df0c359": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_28ac8f3a26ca4c51ab913c482234f3ab",
      "max": 2950825948,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3707cb9b877c451bb245d051c19af8fa",
      "value": 2950825948
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

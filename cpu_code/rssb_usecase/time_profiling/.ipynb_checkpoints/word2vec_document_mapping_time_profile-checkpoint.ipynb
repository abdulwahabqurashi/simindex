{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\me1awq\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing libraries\n",
    "#from numba import cuda\n",
    "import gensim\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import csv\n",
    "import re\n",
    "import time \n",
    "#import pandas as pd\n",
    "#from pandas import DataFrame\n",
    "#import pandas as pd\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"Using device: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"No GPU available, using CPU instead.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading pre=trained word2vec model\n",
    "\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "# You need to dowload google pre-trained model using below link\n",
    "# https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit\n",
    "#Change the path according to your directory\n",
    "\n",
    "model_path = 'C:/Users/me1awq/PhD/docsim/pre_trained_models/GoogleNews_vectors_negative300/GoogleNews_vectors_negative300.bin'   \n",
    "w2v_model = KeyedVectors.load_word2vec_format(model_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/me1awq/PhD/docsim/datasets/rssb/Source rules or OCD rulebook.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Importing Source Rules or OCD Rulebook CSV file\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC:/Users/me1awq/PhD/docsim/datasets/rssb/Source rules or OCD rulebook.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file_object:\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m OCDline \u001b[38;5;129;01min\u001b[39;00m file_object:\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;28mprint\u001b[39m(OCDline)\n",
      "File \u001b[1;32m~\\.conda\\envs\\cpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    277\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m     )\n\u001b[1;32m--> 282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/me1awq/PhD/docsim/datasets/rssb/Source rules or OCD rulebook.csv'"
     ]
    }
   ],
   "source": [
    "# Importing Source Rules or OCD Rulebook CSV file\n",
    "\n",
    "with open ('C:/Users/me1awq/PhD/docsim/datasets/rssb/OCD rulebook.csv') as file_object:\n",
    "    for OCDline in file_object:\n",
    "        print(OCDline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2.1.3 Controls – Operations un- der degraded conditions', '2.1.1.4 - Written operating procedures or spoken instructions when the signalling system cannot be used to preserve the effectiveness of the space interval', '2.3.2 Controls – Level Crossings', '2.6.1.4 The Route Availability (RA) system provides a consistent and simple method for assessing the compatibility of the weight of rail vehicles with the capacity of underline bridges (other than bridges defined as ‘long span’).', '2.2.1.1 The safety benefits of a system for maintaining space intervals between trains (see section 2.1 of this operational concept document) are compromised if a train proceeds without an authority for its movement.', '2.8.6 Controls – railway workforce (Communication between train drivers and signallers)']\n"
     ]
    }
   ],
   "source": [
    "#Sentences tokenization of Source Rules or OCD Rulebook CSV file\n",
    "\n",
    "target_rules = []\n",
    "with open ('C:/Users/me1awq/PhD/docsim/datasets/rssb/OCD rulebook.csv') as file_object:\n",
    "    for trainline in file_object:\n",
    "        tokens_train = sent_tokenize(trainline)\n",
    "        target_rules.extend(tokens_train)\n",
    "\n",
    "    \n",
    "# Searching for text that includes any digits or decimal number. \"\\d\" is looking for digits in tokens\n",
    "\n",
    "withdigits_target_rules=[s for s in target_rules if re.findall(\"^\\d\",s)]\n",
    "print(withdigits_target_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.3 Controls – Operations un- der degraded conditions\n",
      "\n",
      "2.1.1.4 Operating procedures using written or spoken instructions are applied when the signalling system cannot be used to preserve the effectiveness of the space interval:\n",
      "\n",
      "2.3.2 Controls – Level Crossings\n",
      "\n",
      "2.6.1.4 Route availability system provides consistent and simple method to assess compatibility of train weight with underlying bridges\n",
      "\n",
      "2.2.1.1 Safety is compromised if a train proceeds without a movement autority\n",
      "\n",
      "2.8.6 Control communication between train drivers and signallers\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importing Target Rules or EA Rulebook CSV file\n",
    "\n",
    "with open ('C:/Users/me1awq/PhD/docsim/datasets/rssb/EA rulebook.csv') as file_object:\n",
    "    for EAline in file_object:\n",
    "        print(EAline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2.1.3 Controls – Operations un- der degraded conditions', '2.1.1.4 Operating procedures using written or spoken instructions are applied when the signalling system cannot be used to preserve the effectiveness of the space interval:', '2.3.2 Controls – Level Crossings', '2.6.1.4 Route availability system provides consistent and simple method to assess compatibility of train weight with underlying bridges', '2.2.1.1 Safety is compromised if a train proceeds without a movement autority', '2.8.6 Control communication between train drivers and signallers']\n"
     ]
    }
   ],
   "source": [
    "#Sentences tokenization of Target Rules or EA Rulebook CSV file\n",
    "\n",
    "source_rules = []\n",
    "with open ('C:/Users/me1awq/PhD/docsim/datasets/rssb/EA rulebook.csv') as file_object:\n",
    "    for trainline in file_object:\n",
    "        tokens_train = sent_tokenize(trainline)\n",
    "        source_rules.extend(tokens_train)\n",
    "\n",
    "        \n",
    "# Searching for text that includes any digits or decimal number. \"\\d\" is looking for digits in tokens\n",
    "\n",
    "\n",
    "withdigits_source_rules=[s for s in source_rules if re.findall(\"^\\d\",s)]\n",
    "print(withdigits_source_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting Parameters for model\n",
    "\n",
    "class DocSim(object):\n",
    "    def __init__(self, w2v_model , stopwords=[]):\n",
    "        self.w2v_model = w2v_model\n",
    "        self.stopwords = stopwords\n",
    "\n",
    "    def vectorize(self, doc):\n",
    "        \"\"\"Identify the vector values for each word in the given document\"\"\"\n",
    "        doc = doc.lower()\n",
    "        words = [w for w in doc.split(\" \") if w not in self.stopwords]\n",
    "        word_vecs = []\n",
    "        for word in words:\n",
    "            try:\n",
    "                vec = self.w2v_model[word]\n",
    "                word_vecs.append(vec)\n",
    "            except KeyError:\n",
    "                # Ignore, if the word doesn't exist in the vocabulary\n",
    "                pass\n",
    "\n",
    "        # Assuming that document vector is the mean of all the word vectors\n",
    "\n",
    "        vector = np.mean(word_vecs, axis=0)\n",
    "        return vector\n",
    "\n",
    "\n",
    "    def _cosine_sim(self, vecA, vecB):\n",
    "        \"\"\"Find the cosine similarity distance between two vectors.\"\"\"\n",
    "        csim=( np.dot(vecA,vecB) )/ (np.linalg.norm(vecA)*np.linalg.norm(vecB))\n",
    "        if np.isnan(np.sum(csim)):\n",
    "            return 0\n",
    "        return csim\n",
    "\n",
    "    def calculate_similarity(self, withdigits_source_rules, withdigits_target_rules=[], threshold=0.8):\n",
    "        \"\"\"Calculates & returns similarity scores between given source rules & all\n",
    "        the target rules\"\"\"\n",
    "        if isinstance(withdigits_target_rules, str):\n",
    "            withdigits_target_rules = [withdigits_target_rules]\n",
    "\n",
    "\n",
    "        source_vec = self.vectorize(withdigits_source_rules)\n",
    "        results = []\n",
    "        \n",
    "        for rule in withdigits_target_rules:\n",
    "            target_vec = self.vectorize(rule)\n",
    "            sim_score = self._cosine_sim(source_vec, target_vec)\n",
    "            if sim_score > threshold:\n",
    "                results.append({\n",
    "                    'Cosine Sim Score':sim_score,\n",
    "                    'Target Rule':rule\n",
    "                })\n",
    "\n",
    "                \n",
    "            # Sort results by score in desc order\n",
    "            results.sort(key=lambda k : k['Cosine Sim Score'] , reverse=True)\n",
    "\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = DocSim(w2v_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Source rule: 2.1.3 Controls – Operations un- der degraded conditions \n",
      "\n",
      "Similarity with Target Rule is \n",
      "\n",
      " [{'Cosine Sim Score': 1.0, 'Target Rule': '2.1.3 Controls – Operations un- der degraded conditions'}]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Source rule: 2.1.1.4 Operating procedures using written or spoken instructions are applied when the signalling system cannot be used to preserve the effectiveness of the space interval: \n",
      "\n",
      "Similarity with Target Rule is \n",
      "\n",
      " [{'Cosine Sim Score': 0.9575251, 'Target Rule': '2.1.1.4 - Written operating procedures or spoken instructions when the signalling system cannot be used to preserve the effectiveness of the space interval'}]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Source rule: 2.3.2 Controls – Level Crossings \n",
      "\n",
      "Similarity with Target Rule is \n",
      "\n",
      " [{'Cosine Sim Score': 1.0, 'Target Rule': '2.3.2 Controls – Level Crossings'}]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Source rule: 2.6.1.4 Route availability system provides consistent and simple method to assess compatibility of train weight with underlying bridges \n",
      "\n",
      "Similarity with Target Rule is \n",
      "\n",
      " [{'Cosine Sim Score': 0.902249, 'Target Rule': '2.6.1.4 The Route Availability (RA) system provides a consistent and simple method for assessing the compatibility of the weight of rail vehicles with the capacity of underline bridges (other than bridges defined as ‘long span’).'}]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Source rule: 2.2.1.1 Safety is compromised if a train proceeds without a movement autority \n",
      "\n",
      "Similarity with Target Rule is \n",
      "\n",
      " [{'Cosine Sim Score': 0.81305885, 'Target Rule': '2.2.1.1 The safety benefits of a system for maintaining space intervals between trains (see section 2.1 of this operational concept document) are compromised if a train proceeds without an authority for its movement.'}]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Source rule: 2.8.6 Control communication between train drivers and signallers \n",
      "\n",
      "Similarity with Target Rule is \n",
      "\n",
      " [{'Cosine Sim Score': 0.80855364, 'Target Rule': '2.8.6 Controls – railway workforce (Communication between train drivers and signallers)'}]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Calculate the similarity score between a source rule & a target rule.\n",
    "\n",
    "\n",
    "if isinstance(withdigits_source_rules, str):\n",
    "    withdigits_source_rules = [withdigits_source_rules]\n",
    "   \n",
    "\n",
    "# This will return one target rules text with a similarity score\n",
    "\n",
    "for rule in withdigits_source_rules:\n",
    "    sim_scores= ds.calculate_similarity(rule, withdigits_target_rules)\n",
    "\n",
    "    \n",
    "    \n",
    "    # Source Rules are OCD Rules\n",
    "    # Target Rules are EA Rules\n",
    "    \n",
    "    # Printing the output in text file\n",
    "    \n",
    "    print(\"Source rule: {} \\n\\nSimilarity with Target Rule is \\n\\n {}\\n\".format(rule, sim_scores) , file=open(\"output.txt\", \"a\"))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    \n",
    "    # Printing output in Jupyter\n",
    "    \n",
    "    print(\"Source rule: {} \\n\\nSimilarity with Target Rule is \\n\\n {}\\n\".format(rule, sim_scores) )\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120.93860507011414\n"
     ]
    }
   ],
   "source": [
    "end_time = time.time()\n",
    "\n",
    "# calculate the total time taken to execute the code on the CPU\n",
    "total_time = end_time - start_time\n",
    "\n",
    "print(f\"Total time taken to execute the code on CPU: {total_time:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "start=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\NR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing libraries\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import numpy as np\n",
    "import csv\n",
    "import re\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading pre=trained word2vec model\n",
    "\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "# You need to dowload google pre-trained model using below link\n",
    "# https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit\n",
    "#Change the path according to your directory\n",
    "\n",
    "model_path = 'D:\\GoogleNews_vectors_negative300\\GoogleNews_vectors_negative300.bin'   \n",
    "w2v_model = KeyedVectors.load_word2vec_format(model_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting Parameters for model\n",
    "\n",
    "class DocSim(object):\n",
    "    def __init__(self, w2v_model , stopwords=[]):\n",
    "        self.w2v_model = w2v_model\n",
    "        self.stopwords = stopwords\n",
    "\n",
    "    def vectorize(self, doc):\n",
    "        \"\"\"Identify the vector values for each word in the given document\"\"\"\n",
    "        doc = doc.lower()\n",
    "        words = [w for w in doc.split(\" \") if w not in self.stopwords]\n",
    "        word_vecs = []\n",
    "        for word in words:\n",
    "            try:\n",
    "                vec = self.w2v_model[word]\n",
    "                word_vecs.append(vec)\n",
    "            except KeyError:\n",
    "                # Ignore, if the word doesn't exist in the vocabulary\n",
    "                pass\n",
    "\n",
    "        # Assuming that document vector is the mean of all the word vectors\n",
    "\n",
    "        vector = np.mean(word_vecs, axis=0)\n",
    "        return vector\n",
    "    \n",
    "    def jaccard_similarity(self,vecA, vecB):\n",
    "        vectors_minimum=np.minimum(vecA,vecB)\n",
    "        vectors_maximum=np.maximum(vecA,vecB)\n",
    "        jaccard_sim=np.linalg.norm(vectors_minimum)/np.linalg.norm(vectors_maximum)\n",
    "        return jaccard_sim\n",
    "\n",
    "\n",
    "    def calculate_similarity(self, withdigits_source_rules, withdigits_target_rules=[], threshold=0.8):\n",
    "        \"\"\"Calculates & returns similarity scores between given source rules & all\n",
    "        the target rules\"\"\"\n",
    "        if isinstance(withdigits_target_rules, str):\n",
    "            withdigits_target_rules = [withdigits_target_rules]\n",
    "\n",
    "\n",
    "        source_vec = self.vectorize(withdigits_source_rules)\n",
    "        results = []\n",
    "        \n",
    "        for rule in withdigits_target_rules:\n",
    "            target_vec = self.vectorize(rule)\n",
    "            sim_score = self.jaccard_similarity(source_vec, target_vec)\n",
    "            if sim_score > threshold:\n",
    "                results.append({\n",
    "                    'Cosine Sim Score':sim_score,\n",
    "                    'Target Rule':rule\n",
    "                })\n",
    "\n",
    "                \n",
    "            # Sort results by score in desc order\n",
    "            results.sort(key=lambda k : k['Cosine Sim Score'] , reverse=True)\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = DocSim(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.3 Controls – Operations un- der degraded conditions\n",
      "\n",
      "2.1.1.4 - Written operating procedures or spoken instructions when the signalling system cannot be used to preserve the effectiveness of the space interval\n",
      "\n",
      "2.3.2 Controls – Level Crossings\n",
      "\n",
      "2.6.1.4 The Route Availability (RA) system provides a consistent and simple method for assessing the compatibility of the weight of rail vehicles with the capacity of underline bridges (other than bridges defined as ‘long span’).\n",
      "\n",
      "2.2.1.1 The safety benefits of a system for maintaining space intervals between trains (see section 2.1 of this operational concept document) are compromised if a train proceeds without an authority for its movement.\n",
      "\n",
      "2.8.6 Controls – railway workforce (Communication between train drivers and signallers)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importing Source rules or OCD rulebook CSV file\n",
    "\n",
    "with open ('Source rules or OCD rulebook.csv') as file_object:\n",
    "    for EAline in file_object:\n",
    "        print(EAline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2.1.3 Controls – Operations un- der degraded conditions', '2.1.1.4 - Written operating procedures or spoken instructions when the signalling system cannot be used to preserve the effectiveness of the space interval', '2.3.2 Controls – Level Crossings', '2.6.1.4 The Route Availability (RA) system provides a consistent and simple method for assessing the compatibility of the weight of rail vehicles with the capacity of underline bridges (other than bridges defined as ‘long span’).', '2.2.1.1 The safety benefits of a system for maintaining space intervals between trains (see section 2.1 of this operational concept document) are compromised if a train proceeds without an authority for its movement.', '2.8.6 Controls – railway workforce (Communication between train drivers and signallers)']\n"
     ]
    }
   ],
   "source": [
    "#Sentences tokenization of Source rules or OCD rulebook CSV file\n",
    "\n",
    "source_rules = []\n",
    "with open ('Source rules or OCD rulebook.csv') as file_object:\n",
    "    for trainline in file_object:\n",
    "        tokens_train = sent_tokenize(trainline)\n",
    "        source_rules.extend(tokens_train)\n",
    "\n",
    "        \n",
    "# Searching for text that includes any digits or decimal number. \"\\d\" is looking for digits in tokens\n",
    "\n",
    "\n",
    "withdigits_source_rules=[s for s in source_rules if re.findall(\"^\\d\",s)]\n",
    "print(withdigits_source_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.3 Controls – Operations un- der degraded conditions\n",
      "\n",
      "2.1.1.4 Operating procedures using written or spoken instructions are applied when the signalling system cannot be used to preserve the effectiveness of the space interval:\n",
      "\n",
      "2.3.2 Controls – Level Crossings\n",
      "\n",
      "2.6.1.4 Route availability system provides consistent and simple method to assess compatibility of train weight with underlying bridges\n",
      "\n",
      "2.2.1.1 Safety is compromised if a train proceeds without a movement autority\n",
      "\n",
      "2.8.6 Control communication between train drivers and signallers\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importing Target Rules or EA rulebook CSV file\n",
    "\n",
    "with open ('Target Rules or EA rulebook.csv') as file_object:\n",
    "    for OCDline in file_object:\n",
    "        print(OCDline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2.1.3 Controls – Operations un- der degraded conditions', '2.1.1.4 Operating procedures using written or spoken instructions are applied when the signalling system cannot be used to preserve the effectiveness of the space interval:', '2.3.2 Controls – Level Crossings', '2.6.1.4 Route availability system provides consistent and simple method to assess compatibility of train weight with underlying bridges', '2.2.1.1 Safety is compromised if a train proceeds without a movement autority', '2.8.6 Control communication between train drivers and signallers']\n"
     ]
    }
   ],
   "source": [
    "#Sentences tokenization of Target Rules or EA rulebook CSV file\n",
    "\n",
    "target_rules = []\n",
    "with open ('Target Rules or EA rulebook.csv') as file_object:\n",
    "    for trainline in file_object:\n",
    "        tokens_train = sent_tokenize(trainline)\n",
    "        target_rules.extend(tokens_train)\n",
    "\n",
    "    \n",
    "# Searching for text that includes any digits or decimal number. \"\\d\" is looking for digits in tokens\n",
    "\n",
    "withdigits_target_rules=[s for s in target_rules if re.findall(\"^\\d\",s)]\n",
    "print(withdigits_target_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'type' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-0c00bab6f407>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mrule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwithdigits_source_rules\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0msim_scores\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalculate_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwithdigits_target_rules\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-59-8ba9db91a0ef>\u001b[0m in \u001b[0;36mcalculate_similarity\u001b[1;34m(self, withdigits_source_rules, withdigits_target_rules, threshold)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         \u001b[0msource_vec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvectorize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwithdigits_source_rules\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-59-8ba9db91a0ef>\u001b[0m in \u001b[0;36mvectorize\u001b[1;34m(self, doc)\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                 \u001b[0mvec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw2v_model\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m                 \u001b[0mword_vecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'type' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "#Calculate the similarity score between a source rule & a target rule.\n",
    "\n",
    "\n",
    "if isinstance(withdigits_source_rules, str):\n",
    "    withdigits_source_rules = [withdigits_source_rules]\n",
    "   \n",
    "\n",
    "# This will return one target rules text with a similarity score\n",
    "\n",
    "for rule in withdigits_source_rules:\n",
    "    sim_scores= ds.calculate_similarity(rule, withdigits_target_rules)\n",
    "\n",
    "    \n",
    "    \n",
    "    # Source Rules are OCD Rules\n",
    "    # Target Rules are EA Rules\n",
    "    \n",
    "    # Printing the output in text file\n",
    "    \n",
    "    print(\"Source rule: {} \\n\\nSimilarity with Target Rule is \\n\\n {}\\n\".format(rule, sim_scores) , file=open(\"output.txt\", \"a\"))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    \n",
    "    # Printing output in Jupyter\n",
    "    \n",
    "    print(\"Source rule: {} \\n\\nSimilarity with Target Rule is \\n\\n {}\\n\".format(rule, sim_scores) )\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.65496945381165\n"
     ]
    }
   ],
   "source": [
    "done=time.time()\n",
    "elapsed=done-start\n",
    "print(elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NR\\.conda\\envs\\gpuversion1\\lib\\site-packages\\numba\\core\\decorators.py:153: NumbaDeprecationWarning: \u001b[1mThe 'target' keyword argument is deprecated.\u001b[0m\n",
      "  warnings.warn(\"The 'target' keyword argument is deprecated.\", NumbaDeprecationWarning)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'locals'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-80d25be2a652>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m#     return jaccard_sim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;33m@\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;34m\"cuda\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mjaccard_sim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvecA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvecB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;34m\"\"\"Find the cosine similarity distance between two vectors.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\gpuversion1\\lib\\site-packages\\numba\\core\\decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(func)\u001b[0m\n\u001b[0;32m    210\u001b[0m         disp = dispatcher(py_func=func, locals=locals,\n\u001b[0;32m    211\u001b[0m                           \u001b[0mtargetoptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtargetoptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m                           **dispatcher_args)\n\u001b[0m\u001b[0;32m    213\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m             \u001b[0mdisp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_caching\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'locals'"
     ]
    }
   ],
   "source": [
    "from numba import jit, cuda\n",
    "import numpy as np\n",
    "vecA=[4,2,1,1]\n",
    "vecB=[7,8,1,1]\n",
    "\n",
    "\n",
    "# def jaccard_similarity(vecA, vecB):\n",
    "#     vectors_minimum=np.minimum(vecA,vecB)\n",
    "#     vectors_maximum=np.maximum(vecA,vecB)\n",
    "#     jaccard_sim=np.linalg.norm(vectors_minimum)/np.linalg.norm(vectors_maximum)\n",
    "#     return jaccard_sim\n",
    "\n",
    "@jit(target =\"cuda\")\n",
    "def jaccard_sim(self, vecA, vecB):\n",
    "        \"\"\"Find the cosine similarity distance between two vectors.\"\"\"\n",
    "        jsim=(( np.dot(vecA,vecB) ))/((np.linalg.norm(vecA)+np.linalg.norm(vecB)))-(np.dot(vecA,vecB))\n",
    "        if np.isnan(np.sum(jsim)):                   #Test element-wise for NaN and return result as a boolean array.\n",
    "            return 0\n",
    "        return jsim    \n",
    "\n",
    "\n",
    "jaccard_similarity(vecA,vecB)\n",
    "\n",
    "start = timer()\n",
    "jaccard_sim()\n",
    "print(\"with GPU:\", timer()-start)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'locals'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-daf7b2c4f2cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# function optimized to run on gpu\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;33m@\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;34m\"cuda\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfunc2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10000000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\gpuversion1\\lib\\site-packages\\numba\\core\\decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(func)\u001b[0m\n\u001b[0;32m    210\u001b[0m         disp = dispatcher(py_func=func, locals=locals,\n\u001b[0;32m    211\u001b[0m                           \u001b[0mtargetoptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtargetoptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m                           **dispatcher_args)\n\u001b[0m\u001b[0;32m    213\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m             \u001b[0mdisp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_caching\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'locals'"
     ]
    }
   ],
   "source": [
    "from numba import jit, cuda\n",
    "import numpy as np\n",
    "# to measure exec time\n",
    "from timeit import default_timer as timer   \n",
    "  \n",
    "# normal function to run on cpu\n",
    "def func(a):                                \n",
    "    for i in range(10000000):\n",
    "        a[i]+= 1      \n",
    "  \n",
    "# function optimized to run on gpu \n",
    "@jit(target =\"cuda\")                         \n",
    "def func2(a):\n",
    "    for i in range(10000000):\n",
    "        a[i]+= 1\n",
    "if __name__==\"__main__\":\n",
    "    n = 10000000                            \n",
    "    a = np.ones(n, dtype = np.float64)\n",
    "    b = np.ones(n, dtype = np.float32)\n",
    "      \n",
    "    start = timer()\n",
    "    func(a)\n",
    "    print(\"without GPU:\", timer()-start)    \n",
    "      \n",
    "    start = timer()\n",
    "    func2(a)\n",
    "    print(\"with GPU:\", timer()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
